{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed03be0d",
   "metadata": {},
   "source": [
    "### Goals\n",
    "\n",
    "New Concepts:\n",
    "\n",
    "* Using chat messages as our graph state. In the simple-graph notebook we used a string.\n",
    "* Using chat models in graph nodes.\n",
    "* Adding tools (aka Binding tools) to our chat model.\n",
    "* Executing tool calls in graph nodes.\n",
    "\n",
    "![Screenshot 2024-08-21 at 9.24.03 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dd607b08df5e1101_chain1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b42f5",
   "metadata": {},
   "source": [
    "Some sample messages to give as input to chat models. \n",
    "\n",
    "Langchain contains AIMessage, HumanMessage, SystemMessage, ToolMessage as types of messages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d9f6454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"How is your Learning going on so far?\", name=\"Model\")]\n",
    "messages.append(HumanMessage(content=f\"Decent\",name=\"lol\"))\n",
    "messages.append(AIMessage(content=f\"Great, what are you upto now?\", name=\"Model\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn about the tool calling\", name=\"lol\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd78d6e",
   "metadata": {},
   "source": [
    "## Chat Models\n",
    "\n",
    "These models take messages as input and gives message as output.\n",
    "\n",
    "I am trying to use local model that is available here, lets see how many errors i would face :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa46c3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"qwen2.5:7b\")\n",
    "response = llm.invoke(messages)\n",
    "type(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a2a9838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure! Tool calling refers to using tools or external programs from within a programming environment. This can be incredibly useful for leveraging specialized functions that aren\\'t available directly in your primary programming language. Hereâ€™s an overview of how you might implement it:\\n\\n### 1. **Understanding the Basics**\\n   - **Purpose:** To execute external commands or scripts.\\n   - **Languages and Frameworks:** Commonly used languages include Python, Bash (for Unix-like systems), and PowerShell (for Windows).\\n\\n### 2. **Python Example**\\nIn Python, you can use the `subprocess` module to call external tools.\\n\\n#### Using `subprocess.run()`\\n```python\\nimport subprocess\\n\\n# Run a command\\nresult = subprocess.run([\\'ls\\', \\'-l\\'], capture_output=True, text=True)\\nprint(\"Command output:\", result.stdout)\\n\\n# Run another command with input\\noutput = subprocess.run([\\'grep\\', \\'filename.txt\\'], input=b\\'hello\\\\nworld\\\\nfoo\\\\nbar\\', capture_output=True, text=True).stdout\\nprint(output)\\n```\\n\\n#### Using `subprocess.Popen()`\\n```python\\nimport subprocess\\n\\n# Start a process and communicate with it\\np = subprocess.Popen([\\'tail\\', \\'-f\\', \\'log.txt\\'], stdout=subprocess.PIPE)\\nfor line in iter(p.stdout.readline, b\\'\\'):\\n    print(line.strip())\\n```\\n\\n### 3. **Bash Example**\\nIn Bash scripts, you can use the `command` syntax to call external tools.\\n\\n```bash\\n#!/bin/bash\\n\\n# Run a command and capture its output\\noutput=$(ls -l)\\necho \"Directory listing: $output\"\\n\\n# Pass data to another tool\\ngrep_output=$(echo \"hello\\\\nworld\\\\nfoo\\\\nbar\" | grep \\'foo\\')\\necho \"Grep Output: $grep_output\"\\n```\\n\\n### 4. **PowerShell Example**\\nIn PowerShell, you can use the `Start-Process` cmdlet or the `Invoke-Command` approach.\\n\\n```powershell\\n# Run a command and capture its output\\n$output = (Get-ChildItem -Name)\\nWrite-Host \"Directory listing: $output\"\\n\\n# Pass data to another tool\\n$grep_output = (echo \"hello;world;foo;bar\" | Select-String \\'foo\\')\\nWrite-Output \"Grep Output: $grep_output\"\\n```\\n\\n### 5. **Using External Tools in Web Development**\\nIn web development, you might use tools like `npm` or `yarn` to manage packages.\\n\\n```bash\\n# Install a package using npm\\nnpm install express\\n\\n# Run a script with npm\\nnpm run start\\n```\\n\\nThese examples should give you a good starting point for integrating external tools into your projects. If you have any specific needs or questions about these examples, feel free to ask!', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-04-14T04:27:11.0446766Z', 'done': True, 'done_reason': 'stop', 'total_duration': 97742225300, 'load_duration': 38750000, 'prompt_eval_count': 71, 'prompt_eval_duration': 2605000000, 'eval_count': 564, 'eval_duration': 95090000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-29abe050-a0ad-4230-9b85-64fe0a583c28-0', usage_metadata={'input_tokens': 71, 'output_tokens': 564, 'total_tokens': 635})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17fddea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'qwen2.5:7b',\n",
       " 'created_at': '2025-04-14T04:27:11.0446766Z',\n",
       " 'done': True,\n",
       " 'done_reason': 'stop',\n",
       " 'total_duration': 97742225300,\n",
       " 'load_duration': 38750000,\n",
       " 'prompt_eval_count': 71,\n",
       " 'prompt_eval_duration': 2605000000,\n",
       " 'eval_count': 564,\n",
       " 'eval_duration': 95090000000,\n",
       " 'message': Message(role='assistant', content='', images=None, tool_calls=None)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ade0e96",
   "metadata": {},
   "source": [
    "## Tools\n",
    "Tools are for interacting with external systems(API's, Function calls, etc.).\n",
    "\n",
    "They need a schema to be followed and not natural language.\n",
    "\n",
    "The model will choose to call the tool building the schema for it appropriately.\n",
    "\n",
    "We can pass functions as well, so let us pass two functions and see what happens. \n",
    "\n",
    "Multiply and subtract are the functions we shall try on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3e7b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a:int, b:int)->int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a*b\n",
    "def subtract(a:int, b:int)->int:\n",
    "    \"\"\"I want to see if LLM would understand and return correctly in the absence of explanation.\"\"\"\n",
    "    return a-b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply, subtract])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b686b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"What is 2 subtracted from 3\", name=\"Lance\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188380a5",
   "metadata": {},
   "source": [
    "I might sound foolish for stating this, but i actually wanted to check if it would understand the sentence properly and assign 3 to `a` and 2 to `b` or simply assign the numbers in order. \n",
    "\n",
    "* Note that i have not provided any explanation for the subtract function. So i guess it understand the function schema for processing.\n",
    "\n",
    "Good LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e75e2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'subtract',\n",
       "  'args': {'a': 3, 'b': 2},\n",
       "  'id': '15110266-7380-463f-9587-edd76a64e1a4',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb9d1a0",
   "metadata": {},
   "source": [
    "### Building the state of the graph\n",
    "\n",
    "As stated above we use messages for state here.\n",
    "\n",
    "And the problem we face is that at every node the state is overwritten. But we want the messages to be appended at each node.\n",
    "\n",
    "To address this [reducer functions](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) are introduced. A very good explanation is provided in the link.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1ef5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessageState(TypedDict):\n",
    "    message_state: Annotated[list[AnyMessage], add_messages]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff80ae85",
   "metadata": {},
   "source": [
    "### Building Graph\n",
    "\n",
    "A straight forward graph, with a START, TOOL_CALLING_LLM, END.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be1ef9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_calling_llm(state: MessageState):\n",
    "    return {\"message_state\": [llm_with_tools.invoke(state[\"message_state\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ec3c43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "builder = StateGraph(MessageState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "deafa4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='subtract 2 from 3', additional_kwargs={}, response_metadata={}, id='879d9f1e-66ca-4ffa-89bb-3a8d4a65be68'),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-04-14T05:59:30.3870301Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3060709200, 'load_duration': 43355700, 'prompt_eval_count': 239, 'prompt_eval_duration': 619000000, 'eval_count': 25, 'eval_duration': 2393000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-08607036-9dad-4f00-9cc7-2329001f5d56-0', tool_calls=[{'name': 'subtract', 'args': {'a': 3, 'b': 2}, 'id': 'e938ed81-263a-45cb-92cf-c4ec0ebd9d16', 'type': 'tool_call'}], usage_metadata={'input_tokens': 239, 'output_tokens': 25, 'total_tokens': 264})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = graph.invoke({\"message_state\": HumanMessage(content = \"subtract 2 from 3\")})\n",
    "messages['message_state']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084c1741",
   "metadata": {},
   "source": [
    "# Done with this notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
